{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1&Q2 Upload data and load into MySQL\n",
    "\n",
    "Used PSFTP.\n",
    "\n",
    "Used commands recommended.\n",
    "\n",
    "Used DATE format for dates, and other formats as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3&Q4 Observe and key all tables\n",
    "\n",
    "First use id column as primary key for user, subscription and tables:\n",
    "\n",
    "```\n",
    "ALTER TABLE subscriptions ADD PRIMARY KEY (id);\n",
    "\n",
    "ALTER TABLE users ADD PRIMARY KEY (id);\n",
    "\n",
    "ALTER TABLE purchases ADD PRIMARY KEY (id);\n",
    "```\n",
    "\n",
    "And make necessary columns NOT NULL e.g.:\n",
    "\n",
    "```\n",
    "ALTER TABLE assignments MODIFY sub_id INT NOT NULL;\n",
    "```\n",
    "\n",
    "FOREIGN KEY on subscriptions.id:\n",
    "\n",
    "```\n",
    "ALTER TABLE `assignments` \n",
    "ADD FOREIGN KEY(`sub_id`) \n",
    "REFERENCES subscriptions(id);\n",
    "```\n",
    "FOREIGN KEY on users.id:\n",
    "\n",
    "```\n",
    "ALTER TABLE `purchases` \n",
    "ADD FOREIGN KEY(`user_id`) \n",
    "REFERENCES users(id);\t\n",
    "\n",
    "ALTER TABLE `subscriptions` \n",
    "ADD FOREIGN KEY(`user_id`) \n",
    "REFERENCES users(id);\t\n",
    "```\n",
    "Join works much better now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 What's wrong with data set?\n",
    "\n",
    "Let's test user signup type against test group assignment.\n",
    "\n",
    "```\n",
    "select signup_platform, test_group, COUNT(*) as count_users\n",
    "from assignments\n",
    "join subscriptions\n",
    "on subscriptions.id = assignments.sub_id\n",
    "join users\n",
    "on subscriptions.user_id=users.id\n",
    "group by signup_platform, test_group;\n",
    "\n",
    "+-----------------+------------+-------------+\n",
    "| signup_platform | test_group | count_users |\n",
    "+-----------------+------------+-------------+\n",
    "| android         | control    |       16233 |\n",
    "| android         | test       |       16409 |\n",
    "| ios             | control    |       23444 |\n",
    "| ios             | test       |       23727 |\n",
    "| web             | control    |       37242 |\n",
    "| web             | test       |       37233 |\n",
    "+-----------------+------------+-------------+\n",
    "\n",
    "```\n",
    "\n",
    "Looks OK.\n",
    "\n",
    "How about sign-ups per month by signup-platform?\n",
    "\n",
    "```\n",
    "select count(*) as number,year(start_date) as year,month(start_date) as month,signup_platform \n",
    "from subscriptions\n",
    "join users\n",
    "on subscriptions.user_id=users.id\n",
    "group by year(start_date) ,month(start_date) ,signup_platform\n",
    "```\n",
    "\n",
    "The result is 123 lines long so I'll show the important part.\n",
    "\n",
    "```\n",
    "+--------+------+-------+-----------------+\n",
    "| number | year | month | signup_platform |\n",
    "+--------+------+-------+-----------------+\n",
    "|     14 | 2012 |     1 | web             |\n",
    "|     32 | 2012 |     2 | web             |\n",
    "|     69 | 2012 |     3 | web             |\n",
    "|     99 | 2012 |     4 | web             |\n",
    "...\n",
    "|    779 | 2013 |    10 | web             |\n",
    "|   2188 | 2013 |    11 | web             |\n",
    "|   2451 | 2013 |    12 | web             |\n",
    "|     19 | 2014 |     1 | android         |\n",
    "|     22 | 2014 |     1 | ios             |\n",
    "|    943 | 2014 |     1 | web             |\n",
    "|     54 | 2014 |     2 | android         |\n",
    "|     78 | 2014 |     2 | ios             |\n",
    "|    913 | 2014 |     2 | web             |\n",
    "...\n",
    "```\n",
    "It looks like android and ios were ignored before 2014. That could be because there were no users, or because the users were lumped together until 2014 and then migrated to a new table after that to segment the users.\n",
    "\n",
    "Some other possible issues:\n",
    "\n",
    "Purchases can not be uniquely matched to subscriptions, since users may have multiple subscriptions.\n",
    "\n",
    "There are ~3x subscriptions starting in november & december compared to other months.\n",
    "\n",
    "There are 2 duplicate IP addresses.\n",
    "\n",
    "Most of the names are duplicate/triplicate.\n",
    "\n",
    "Twice the purchase amount in January compared to any other month.\n",
    "\n",
    "All the purchases are roughly the same value, wouldn't make sense for a Costco-like store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 Evaluate AB Test\n",
    "\n",
    "First, let's count up the total number of subscriptions that are active in the test period.\n",
    "\n",
    "We need to select accounts that ended AFTER 2016-07-01, or are still active, end-date = NULL.\n",
    "\n",
    "```\n",
    "select test_group, count(*) from \n",
    "(\n",
    "select s.id, test_group from subscriptions s \n",
    "join assignments \n",
    "on s.id=sub_id \n",
    "where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    ") as tab\n",
    "group by test_group;\n",
    "\n",
    "+------------+----------+\n",
    "| test_group | count(*) |\n",
    "+------------+----------+\n",
    "| control    |    17439 |\n",
    "| test       |    24933 |\n",
    "+------------+----------+\n",
    "2 rows in set (0.00 sec)\n",
    "\n",
    "```\n",
    "This seems a little unbalanced, so it appears that the test group and control group are not assigned completely at random. Let's see if there is any counfounding by the number of accounts started after the start date:\n",
    "\n",
    "```\n",
    "select test_group, count(*) from \n",
    "(\n",
    "select s.id, test_group from subscriptions s \n",
    "join assignments \n",
    "on s.id=sub_id \n",
    "where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    "and (start_date > '2016-07-01')\n",
    ") as tab\n",
    "group by test_group;\n",
    "\n",
    "+------------+----------+\n",
    "| test_group | count(*) |\n",
    "+------------+----------+\n",
    "| control    |     6225 |\n",
    "| test       |     6432 |\n",
    "+------------+----------+\n",
    "2 rows in set (0.15 sec)\n",
    "\n",
    "```\n",
    "\n",
    "So the fraction of new users in control is 6225/17439 = 0.3569\n",
    "\n",
    "And test, 6432/24933 = 0.2579\n",
    "\n",
    "So... this seems quite skewed. We should restrict the test to only accounts started after the start date.\n",
    "\n",
    "Now let's address another possible problem. Purchases cannot be uniquely assigned to a subscription. Let's see if any of the users are assigned to duplicate user account\n",
    "\n",
    "```\n",
    "select user_id, count(*) from (\n",
    "select s.id,user_id, test_group \n",
    "from subscriptions s \n",
    "join assignments \n",
    "on \n",
    "s.id=sub_id \n",
    "where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    "and (start_date < '2016-07-01')\n",
    ") as tab group by user_id having count(*) > 1;\n",
    "\n",
    "+---------+----------+\n",
    "| user_id | count(*) |\n",
    "+---------+----------+\n",
    "|   57891 |        2 |\n",
    "|   89857 |        2 |\n",
    "|  110382 |        2 |\n",
    "|  121530 |        2 |\n",
    "|  134665 |        2 |\n",
    "|  135397 |        2 |\n",
    "|  136783 |        2 |\n",
    "|  137577 |        2 |\n",
    "|  140524 |        2 |\n",
    "+---------+----------+\n",
    "9 rows in set (0.00 sec)\n",
    "\n",
    "```\n",
    "\n",
    "So there are 9 users (18 subscriptions) that may double-count purchases.\n",
    "\n",
    "Let's see what the total value of purchases are here to see if this may somehow strongly skew the results.\n",
    "\n",
    "```\n",
    "select tabb.user_id, sum(amount) as amount_per_user from\n",
    "(\n",
    "    select user_id, count(*) from (\n",
    "    select s.id,user_id, test_group \n",
    "    from subscriptions s \n",
    "    join assignments \n",
    "    on \n",
    "    s.id=sub_id \n",
    "    where ((end_date >= '2016-07-01') or (end_date IS NULL))\n",
    "    and (start_date < '2016-07-01')\n",
    "    ) as tab group by user_id having count(*) > 1\n",
    ") as tabb \n",
    "join purchases\n",
    "on tabb.user_id = purchases.user_id\n",
    "group by user_id;\n",
    "\n",
    "Empty set (0.17 sec)\n",
    "\n",
    "```\n",
    "\n",
    "So none of these double account users actually made purchases, so there's no need to actually take them out.\n",
    "\n",
    "Now let's finally count up the summary statistics, average and standard dev of purchase amount per subscriber.\n",
    "\n",
    "Something to note: we need to restrict user accounts AND purchases by date.\n",
    "\n",
    "```\n",
    "select test_group, avg(tot_per_user) as avg, stddev(tot_per_user) as std from\n",
    "(\n",
    "    select user_id,sum(amount) as tot_per_user,test_group from\n",
    "    (\n",
    "        select s.id,s.user_id,IFNULL(p.amount, 0) as amount,a.test_group,p.date\n",
    "        from subscriptions s \n",
    "        join assignments a\n",
    "        on s.id=sub_id \n",
    "        left join purchases p\n",
    "        on p.user_id = s.user_id \n",
    "        where ((end_date >= '2016-07-01') or (end_date IS NULL))\n",
    "        and ((p.date >= '2016-07-01') or (p.date IS NULL))\n",
    "        and (start_date < '2016-07-01')\n",
    "    ) as sums\n",
    "    group by user_id\n",
    ") as final\n",
    "group by test_group;\n",
    "\n",
    "+------------+-----------+----------+\n",
    "| test_group | avg       | std      |\n",
    "+------------+-----------+----------+\n",
    "| control    | 10.515799 | 9.998874 |\n",
    "| test       |  6.403731 | 9.386374 |\n",
    "+------------+-----------+----------+\n",
    "\n",
    "```\n",
    "\n",
    "WOW! Looks like this change is pretty bad! Abort immediately. Let's just check without removing the user accounts started after the start date:\n",
    "\n",
    "```\n",
    "\n",
    "select test_group, avg(tot_per_user) as avg, stddev(tot_per_user) as std from\n",
    "(\n",
    "    select user_id,sum(amount) as tot_per_user,test_group from\n",
    "    (\n",
    "        select s.id,s.user_id,IFNULL(p.amount, 0) as amount,a.test_group,p.date\n",
    "        from subscriptions s \n",
    "        join assignments a\n",
    "        on s.id=sub_id \n",
    "        left join purchases p\n",
    "        on p.user_id = s.user_id \n",
    "        where ((end_date >= '2016-07-01') or (end_date IS NULL))\n",
    "        and ((p.date >= '2016-07-01') or (p.date IS NULL))\n",
    "    ) as sums\n",
    "    group by user_id\n",
    ") as final\n",
    "group by test_group;\n",
    "\n",
    "+------------+-----------+-----------+\n",
    "| test_group | avg       | std       |\n",
    "+------------+-----------+-----------+\n",
    "| control    | 12.713398 | 10.963197 |\n",
    "| test       |  9.343056 | 11.220407 |\n",
    "+------------+-----------+-----------+\n",
    "\n",
    "```\n",
    "\n",
    "Still bad! OK now let's do the t-test of significance.\n",
    "\n",
    "The test statistic will be:\n",
    "\n",
    "$t_{n1+n2-2} = \\dfrac { \\overline{X_1} - \\overline{X_2} } { \\sigma \\sqrt { \\tfrac{1}{n_1} + \\tfrac{1}{n_12} } } $\n",
    "\n",
    "Assuming that the distributions have roughly equal variance (and they appear to).\n",
    "\n",
    "Note, the underlying population distributions are definitely not normal, and appear to have right-skew, but the sample means should be approximately normal because we have high numbers of samples.\n",
    "\n",
    "Let's get the actual number of units in each sample:\n",
    "\n",
    "```\n",
    "select test_group, count(*) from \n",
    "(\n",
    "select s.id, test_group from subscriptions s \n",
    "join assignments \n",
    "on s.id=sub_id \n",
    "where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    "and (start_date < '2016-07-01')\n",
    ") as tab\n",
    "group by test_group;\n",
    "\n",
    "+------------+----------+\n",
    "| test_group | count(*) |\n",
    "+------------+----------+\n",
    "| control    |    11117 |\n",
    "| test       |    18395 |\n",
    "+------------+----------+\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic = 35.6627789552\n",
      "cumulative distribution =  1.0\n",
      "p-val =  0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "tval = (10.33 - 6.26)/(9.5)/((1/11117.0 + 1/18395.0)**0.5)\n",
    "print 't-statistic =', tval\n",
    "\n",
    "print 'cumulative distribution = ', t.cdf(tval, 11117 + 18395, loc=0, scale=1)\n",
    "p = 2* (1-t.cdf(tval, 11117 + 18395, loc=0, scale=1))\n",
    "print 'p-val = ', p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a power calculation. Let's just do a calculation on what kind of sample size we would need to detect the kind of difference we have with 80% power.\n",
    "\n",
    "So in other words $P(t_{stat} > t_{crit} | \\mu_1 - \\mu_2 = 4.07) = 80\\%$\n",
    "\n",
    "For a 2 sided t-test, t-crit ~ 2 (depending on df, we can check this assumption later).\n",
    "\n",
    "The true calculation here is:\n",
    "\n",
    "$P(t_{df} > (2 - E[t_{stat}]) = 0.8$\n",
    "\n",
    "Here we will simplify the t-distribution to a normal one, (we can check the validity of this later).\n",
    "\n",
    "So we are looking for a value that a random normal will be greater than, 80% of the time.\n",
    "\n",
    "This is just $CDF^{-1}(0.2) = -0.841621$\n",
    "\n",
    "$2 - \\dfrac{4.07}{9.5\\sqrt{\\tfrac{2}{n}}} = -0.841621$\n",
    "\n",
    "Where n is the number in each sample (assuming equal).\n",
    "\n",
    "$ n = ((2+0.84)*\\sqrt2 * 9.5 / 4.07)^2 $\n",
    "\n",
    "$(2.84*1.41*9.5/4.07)^2 = 87 $ so we expect to get 80% power with n~90, we have more than 10,000.\n",
    "\n",
    "The assumption of normality holds up. At $df\\sim2*90$, the t-distribution is nearly normal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7 Company evaluation\n",
    "\n",
    "We can look at how sales are changing month to month:\n",
    "\n",
    "```\n",
    "select sum(amount) from purchases group by month(date);\n",
    "\n",
    "+-------------+\n",
    "| sum(amount) |\n",
    "+-------------+\n",
    "|   254272.05 |\n",
    "|   164846.26 |\n",
    "|   110667.99 |\n",
    "|   104222.72 |\n",
    "|   141337.98 |\n",
    "|   141637.65 |\n",
    "|   160638.66 |\n",
    "|   166556.71 |\n",
    "|     5380.47 |\n",
    "+-------------+\n",
    "\n",
    "```\n",
    "\n",
    "There's a steep dropoff after January, (after-holiday sales?) but otherwise it looks mostly stable-ish. \n",
    "\n",
    "Also, we can count number of subscriptions beginning (and that have ended) in each year:\n",
    "\n",
    "```\n",
    "select year(start_date), count(*) as total, count(end_date) as churned from subscriptions group by year(start_date); \n",
    "\n",
    "\n",
    "+------------------+-------+---------+\n",
    "| year(start_date) | total | churned |\n",
    "+------------------+-------+---------+\n",
    "|             2012 |  3870 |    3828 |\n",
    "|             2013 | 10815 |   10564 |\n",
    "|             2014 | 31351 |   30121 |\n",
    "|             2015 | 62568 |   56017 |\n",
    "|             2016 | 45684 |   22751 |\n",
    "+------------------+-------+---------+\n",
    "\n",
    "```\n",
    "\n",
    "So it looks like overall there is pretty healthy growth in new subscriptions overall, but the churn seems high... only ~10% of subscriptions starting in 2015 are still current. About 50% of subscriptions this year have already churned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8 Active user table\n",
    "\n",
    "First create a date table with all dates from:\n",
    "\n",
    "1/9/2012 - 9/1/2016\n",
    "```\n",
    "DROP PROCEDURE IF EXISTS filldates;\n",
    "DELIMITER |\n",
    "CREATE PROCEDURE filldates(dateStart DATE, dateEnd DATE)\n",
    "BEGIN\n",
    "  WHILE dateStart <= dateEnd DO\n",
    "    INSERT INTO _date (datelist) VALUES (dateStart);\n",
    "    SET dateStart = date_add(dateStart, INTERVAL 1 DAY);\n",
    "  END WHILE;\n",
    "END;\n",
    "|\n",
    "DELIMITER ;\n",
    "CALL filldates('2012-01-09','2016-09-01');\n",
    "\n",
    "SELECT * FROM _date;\n",
    "\n",
    "...\n",
    "| 2016-08-27 |\n",
    "| 2016-08-28 |\n",
    "| 2016-08-29 |\n",
    "| 2016-08-30 |\n",
    "| 2016-08-31 |\n",
    "| 2016-09-01 |\n",
    "+------------+\n",
    "```\n",
    "\n",
    "Try to make the table\n",
    "\n",
    "```\n",
    "SELECT \n",
    "user_id, \n",
    "datelist as date, \n",
    "    (case \n",
    "    when end_date IS NULL\n",
    "    then TRUE\n",
    "    when (end_date IS NOT NULL) and (datelist<end_date)\n",
    "    then TRUE\n",
    "    else FALSE\n",
    "    end) as is_active ,\n",
    "start_date as signup_date,\n",
    "signup_platform  \n",
    "from subscriptions \n",
    "join _date \n",
    "on start_date<datelist \n",
    "join users \n",
    "on users.id = user_id\n",
    "WHERE user_id BETWEEN 100000 AND 105000;\n",
    "\n",
    "|  104997 | 2016-09-01 |         0 | 2015-12-25  | ios             |\n",
    "|  104998 | 2016-09-01 |         0 | 2015-12-25  | ios             |\n",
    "|  104999 | 2016-09-01 |         0 | 2015-12-25  | ios             |\n",
    "|  105000 | 2016-09-01 |         0 | 2015-12-25  | ios             |\n",
    "+---------+------------+-----------+-------------+-----------------+\n",
    "1288429 rows in set (1.97 sec)\n",
    "\n",
    "(FALSE evaluates to 0)\n",
    "\n",
    "```\n",
    "\n",
    "...and MySQL crashes if you don't restrict user_id\n",
    "\n",
    "One problem with this query is that there will be duplicate rows because of the users/subscriptions problem. For example, on a given day, a user's old subscription will be inactive (is_active = False), but their new one could be active (is_active = True).\n",
    "\n",
    "To solve this, we can use max(is_active) as is_active, and group by user_id. $Max(True,False) = True$, so if the user has at least one active subscription on that day, they will be counted as active.\n",
    "\n",
    "```\n",
    "SELECT \n",
    "user_id, \n",
    "datelist as date, \n",
    "    max(case \n",
    "    when end_date IS NULL\n",
    "    then TRUE\n",
    "    when (end_date IS NOT NULL) and (datelist<end_date)\n",
    "    then TRUE\n",
    "    else FALSE\n",
    "    end) as is_active ,\n",
    "start_date as signup_date,\n",
    "signup_platform\n",
    "from subscriptions \n",
    "join _date \n",
    "on start_date<datelist \n",
    "join users \n",
    "on users.id = user_id\n",
    "WHERE user_id BETWEEN 100000 AND 105000\n",
    "GROUP BY users.id,date;\n",
    "LIMIT 30;\n",
    "\n",
    "|  105000 | 2016-08-29 |         0 | 2015-12-25  | ios             |\n",
    "|  105000 | 2016-08-30 |         0 | 2015-12-25  | ios             |\n",
    "|  105000 | 2016-08-31 |         0 | 2015-12-25  | ios             |\n",
    "|  105000 | 2016-09-01 |         0 | 2015-12-25  | ios             |\n",
    "+---------+------------+-----------+-------------+-----------------+\n",
    "1284690 rows in set (14.92 sec)\n",
    "\n",
    "```\n",
    "\n",
    "Warning: this query is much slower. I did it all through once to look at the number of rows and compare. As expected there are a few less rows in this one because it eliminates the duplicate user rows.\n",
    "\n",
    "To make it more efficient you could only add today's entries. Entries from the past would not change.\n",
    "\n",
    "Let's count churn by date.\n",
    "\n",
    "```\n",
    "SELECT end_date, count(end_date) as num_churn from subscriptions group by end_date;\n",
    "\n",
    "+------------+-----------+\n",
    "| end_date   | num_churn |\n",
    "+------------+-----------+\n",
    "...\n",
    "...\n",
    "...\n",
    "| 2016-08-24 |       182 |\n",
    "| 2016-08-25 |       178 |\n",
    "| 2016-08-26 |       185 |\n",
    "| 2016-08-27 |       187 |\n",
    "| 2016-08-28 |       196 |\n",
    "| 2016-08-29 |       182 |\n",
    "| 2016-08-30 |       189 |\n",
    "| 2016-08-31 |       185 |\n",
    "| 2016-09-01 |       176 |\n",
    "+------------+-----------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9 Annual vs monthly\n",
    "\n",
    "We can look at the purchase amount this year, grouped by subscription type:\n",
    "\n",
    "```\n",
    "select sum(amount), sub_type \n",
    "from purchases \n",
    "join subscriptions \n",
    "on subscriptions.user_id = purchases.user_id \n",
    "group by sub_type;\n",
    "\n",
    "+-------------+----------+\n",
    "| sum(amount) | sub_type |\n",
    "+-------------+----------+\n",
    "|    91742.75 | annual   |\n",
    "|  1178183.30 | monthly  |\n",
    "+-------------+----------+\n",
    "\n",
    "```\n",
    "So at the moment we definitely get more sales from monthly subscribers. But how is the trend over time?\n",
    "\n",
    "```\n",
    "select sum(amount),month(purchases.date) ,sub_type\n",
    "from purchases \n",
    "join subscriptions \n",
    "on subscriptions.user_id = purchases.user_id \n",
    "group by sub_type,month(purchases.date);\n",
    "\n",
    "+-------------+-----------------------+----------+\n",
    "| sum(amount) | month(purchases.date) | sub_type |\n",
    "+-------------+-----------------------+----------+\n",
    "|    10220.28 |                     1 | annual   |\n",
    "|    10203.81 |                     2 | annual   |\n",
    "|     8785.60 |                     3 | annual   |\n",
    "|     8722.01 |                     4 | annual   |\n",
    "|    11401.93 |                     5 | annual   |\n",
    "|    12079.09 |                     6 | annual   |\n",
    "|    14386.55 |                     7 | annual   |\n",
    "|    15425.77 |                     8 | annual   |\n",
    "|      517.71 |                     9 | annual   |\n",
    "|   247112.58 |                     1 | monthly  |\n",
    "|   156842.20 |                     2 | monthly  |\n",
    "|   104078.02 |                     3 | monthly  |\n",
    "|    97504.86 |                     4 | monthly  |\n",
    "|   132539.72 |                     5 | monthly  |\n",
    "|   131965.19 |                     6 | monthly  |\n",
    "|   149088.15 |                     7 | monthly  |\n",
    "|   154105.76 |                     8 | monthly  |\n",
    "|     4946.82 |                     9 | monthly  |\n",
    "+-------------+-----------------------+----------+\n",
    "\n",
    "```\n",
    "Besides an odd fluke at the beginning of the year, there appears to be similar growth, but annual appears to have the edge.\n",
    "\n",
    "We can also look at growth rates and churn for different subscription types:\n",
    "\n",
    "```\n",
    "select count(end_date) as churned,count(*) as total, year(start_date) as year, sub_type\n",
    "from subscriptions\n",
    "group by year(start_date),sub_type;\n",
    "\n",
    "+---------+-------+------+----------+\n",
    "| churned | total | year | sub_type |\n",
    "+---------+-------+------+----------+\n",
    "|     294 |   336 | 2012 | annual   |\n",
    "|    3534 |  3534 | 2012 | monthly  |\n",
    "|     990 |  1241 | 2013 | annual   |\n",
    "|    9574 |  9574 | 2013 | monthly  |\n",
    "|    2147 |  3370 | 2014 | annual   |\n",
    "|   27974 | 27981 | 2014 | monthly  |\n",
    "|    2258 |  7386 | 2015 | annual   |\n",
    "|   53759 | 55182 | 2015 | monthly  |\n",
    "|       0 |  7500 | 2016 | annual   |\n",
    "|   22751 | 38184 | 2016 | monthly  |\n",
    "+---------+-------+------+----------+\n",
    "\n",
    "```\n",
    "Annual subscribers churn much more slowly, and appear to be growing a little bit faster. Soat the moment there are ~20,000 monthly users and ~12,000 annual users, but that will change over time. In the long run annual users will overtake, if trends hold. However, in the short run monthly users make much more purchases.\n",
    "\n",
    "For the short term, the change should definitely be made. Expected revenue increase would be ~ 0.10 * (1,200,000 - 100,000) = 110,000. Annualized this would be about 110,000/8*12 = 165,000\n",
    "\n",
    "In the long run, if annual users continue to grow, the change should be reversed."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
