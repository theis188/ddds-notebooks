{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1&Q2 Upload data and load into MySQL\n",
    "\n",
    "Used PSFTP.\n",
    "\n",
    "Used commands recommended.\n",
    "\n",
    "Used DATE format for dates, and other formats as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3&Q4 Observe and key all tables\n",
    "\n",
    "First use id column as primary key for user, subscription and tables:\n",
    "\n",
    "```\n",
    "ALTER TABLE subscriptions ADD PRIMARY KEY (id);\n",
    "\n",
    "ALTER TABLE users ADD PRIMARY KEY (id);\n",
    "\n",
    "ALTER TABLE purchases ADD PRIMARY KEY (id);\n",
    "```\n",
    "\n",
    "And make necessary columns NOT NULL e.g.:\n",
    "\n",
    "```\n",
    "ALTER TABLE assignments MODIFY sub_id INT NOT NULL;\n",
    "```\n",
    "\n",
    "FOREIGN KEY on subscriptions.id:\n",
    "\n",
    "```\n",
    "ALTER TABLE `assignments` \n",
    "ADD FOREIGN KEY(`sub_id`) \n",
    "REFERENCES subscriptions(id);\n",
    "```\n",
    "FOREIGN KEY on users.id:\n",
    "\n",
    "```\n",
    "ALTER TABLE `purchases` \n",
    "ADD FOREIGN KEY(`user_id`) \n",
    "REFERENCES users(id);\t\n",
    "\n",
    "ALTER TABLE `subscriptions` \n",
    "ADD FOREIGN KEY(`user_id`) \n",
    "REFERENCES users(id);\t\n",
    "```\n",
    "Join works much better now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 What's wrong with data set?\n",
    "\n",
    "<strong>Purchases can not be uniquely matched to subscriptions, since users may have multiple subscriptions.</strong>\n",
    "\n",
    "Some other possible issues:\n",
    "\n",
    "There are ~3x subscriptions starting in november & december compared to other months.\n",
    "\n",
    "There are 2 duplicate IP addresses.\n",
    "\n",
    "Most of the names are duplicate/triplicate.\n",
    "\n",
    "Twice the purchase amount in January compared to any other month.\n",
    "\n",
    "All the purchases are roughly the same value, wouldn't make sense for a Costco-like store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 Evaluate AB Test\n",
    "\n",
    "First, let's count up the total number of subscriptions that are active in the test period.\n",
    "\n",
    "We need to select accounts that ended AFTER 2016-07-01, or are still active, end-date = NULL.\n",
    "\n",
    "```\n",
    "select test_group, count(*) from \n",
    "(\n",
    "select s.id, test_group from subscriptions s \n",
    "join assignments \n",
    "on s.id=sub_id \n",
    "where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    ") as tab\n",
    "group by test_group;\n",
    "\n",
    "+------------+----------+\n",
    "| test_group | count(*) |\n",
    "+------------+----------+\n",
    "| control    |    17439 |\n",
    "| test       |    24933 |\n",
    "+------------+----------+\n",
    "2 rows in set (0.00 sec)\n",
    "\n",
    "```\n",
    "This seems a little unbalanced, so it appears that the test group and control group are not assigned completely at random. Let's see if there is any counfounding by the number of accounts started after the start date:\n",
    "\n",
    "```\n",
    "select test_group, count(*) from \n",
    "(\n",
    "select s.id, test_group from subscriptions s \n",
    "join assignments \n",
    "on s.id=sub_id \n",
    "where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    "and (start_date > '2016-07-01')\n",
    ") as tab\n",
    "group by test_group;\n",
    "\n",
    "+------------+----------+\n",
    "| test_group | count(*) |\n",
    "+------------+----------+\n",
    "| control    |     6225 |\n",
    "| test       |     6432 |\n",
    "+------------+----------+\n",
    "2 rows in set (0.15 sec)\n",
    "\n",
    "```\n",
    "\n",
    "So the fraction of new users in control is 6225/17439 = 0.3569\n",
    "\n",
    "And test, 6432/24933 = 0.2579\n",
    "\n",
    "So... this seems quite skewed. We should restrict the test to only accounts started after the start date.\n",
    "\n",
    "Now let's address another possible problem. Purchases cannot be uniquely assigned to a subscription. Let's see if any of the users are assigned to duplicate user account\n",
    "\n",
    "```\n",
    "select user_id, count(*) from (\n",
    "select s.id,user_id, test_group \n",
    "from subscriptions s \n",
    "join assignments \n",
    "on \n",
    "s.id=sub_id \n",
    "where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    "and (start_date < '2016-07-01')\n",
    ") as tab group by user_id having count(*) > 1;\n",
    "\n",
    "+---------+----------+\n",
    "| user_id | count(*) |\n",
    "+---------+----------+\n",
    "|   57891 |        2 |\n",
    "|   89857 |        2 |\n",
    "|  110382 |        2 |\n",
    "|  121530 |        2 |\n",
    "|  134665 |        2 |\n",
    "|  135397 |        2 |\n",
    "|  136783 |        2 |\n",
    "|  137577 |        2 |\n",
    "|  140524 |        2 |\n",
    "+---------+----------+\n",
    "9 rows in set (0.00 sec)\n",
    "\n",
    "```\n",
    "\n",
    "So there are 9 users (18 subscriptions) that may double-count purchases.\n",
    "\n",
    "Let's see what the total value of purchases are here to see if this may somehow strongly skew the results.\n",
    "\n",
    "```\n",
    "select tabb.user_id, sum(amount) as amount_per_user from\n",
    "(\n",
    "    select user_id, count(*) from (\n",
    "    select s.id,user_id, test_group \n",
    "    from subscriptions s \n",
    "    join assignments \n",
    "    on \n",
    "    s.id=sub_id \n",
    "    where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    "    and (start_date < '2016-07-01')\n",
    "    ) as tab group by user_id having count(*) > 1\n",
    ") as tabb \n",
    "join purchases\n",
    "on tabb.user_id = purchases.user_id\n",
    "group by user_id;\n",
    "\n",
    "Empty set (0.17 sec)\n",
    "\n",
    "```\n",
    "\n",
    "So none of these double account users actually made purchases, so there's no need to actually take them out.\n",
    "\n",
    "Now let's finally count up the summary statistics, average and standard dev of purchase amount per subscriber.\n",
    "\n",
    "Something to note: we need to restrict user accounts AND purchases by date.\n",
    "\n",
    "```\n",
    "select test_group, avg(tot_per_user) as avg, stddev(tot_per_user) as std from\n",
    "(\n",
    "    select user_id,sum(amount) as tot_per_user,test_group from\n",
    "    (\n",
    "        select s.id,s.user_id,IFNULL(amount, 0) as amount,test_group,purchases.date\n",
    "        from subscriptions s \n",
    "        join assignments \n",
    "        on s.id=sub_id \n",
    "        left join purchases \n",
    "        on purchases.user_id = s.user_id \n",
    "        where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    "        and ((purchases.date > '2016-07-01') or (purchases.date IS NULL))\n",
    "        and (start_date < '2016-07-01')\n",
    "    ) as sums\n",
    "    group by user_id\n",
    ") as final\n",
    "group by test_group;\n",
    "\n",
    "+------------+-----------+----------+\n",
    "| test_group | avg       | std      |\n",
    "+------------+-----------+----------+\n",
    "| control    | 10.331976 | 9.812589 |\n",
    "| test       |  6.261994 | 9.211428 |\n",
    "+------------+-----------+----------+\n",
    "\n",
    "```\n",
    "\n",
    "WOW! Looks like this change SUCKS! Abort immediately. Let's just check without removing the user accounts started after the start date:\n",
    "\n",
    "```\n",
    "\n",
    "select test_group, avg(tot_per_user) as avg, stddev(tot_per_user) as std from\n",
    "(\n",
    "    select user_id,sum(amount) as tot_per_user,test_group from\n",
    "    (\n",
    "        select s.id,s.user_id,IFNULL(amount, 0) as amount,test_group,purchases.date\n",
    "        from subscriptions s \n",
    "        join assignments \n",
    "        on s.id=sub_id \n",
    "        left join purchases \n",
    "        on purchases.user_id = s.user_id \n",
    "        where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    "        and ((purchases.date > '2016-07-01') or (purchases.date IS NULL))\n",
    "    ) as sums\n",
    "    group by user_id\n",
    ") as final\n",
    "group by test_group;\n",
    "\n",
    "+------------+-----------+-----------+\n",
    "| test_group | avg       | std       |\n",
    "+------------+-----------+-----------+\n",
    "| control    | 12.636420 | 10.898481 |\n",
    "| test       |  9.269383 | 11.154681 |\n",
    "+------------+-----------+-----------+\n",
    "\n",
    "```\n",
    "\n",
    "Still SUCKS! OK now let's do the t-test of significance.\n",
    "\n",
    "The test statistic will be:\n",
    "\n",
    "$t_{n1+n2-2} = \\dfrac { \\overline{X_1} - \\overline{X_2} } { \\sigma \\sqrt { \\tfrac{1}{n_1} + \\tfrac{1}{n_12} } } $\n",
    "\n",
    "Assuming that the distributions have roughly equal variance (and they appear to).\n",
    "\n",
    "Note, the underlying population distributions are definitely not normal, and appear to have right-skew, but the sample means should be approximately normal because we have high numbers of samples.\n",
    "\n",
    "Let's get the actual number of units in each sample:\n",
    "\n",
    "```\n",
    "select test_group, count(*) from \n",
    "(\n",
    "select s.id, test_group from subscriptions s \n",
    "join assignments \n",
    "on s.id=sub_id \n",
    "where ((end_date > '2016-07-01') or (end_date IS NULL))\n",
    "and (start_date < '2016-07-01')\n",
    ") as tab\n",
    "group by test_group;\n",
    "\n",
    "+------------+----------+\n",
    "| test_group | count(*) |\n",
    "+------------+----------+\n",
    "| control    |    11117 |\n",
    "| test       |    18395 |\n",
    "+------------+----------+\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic = 35.6627789552\n",
      "cumulative distribution =  1.0\n",
      "p-val =  0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "tval = (10.33 - 6.26)/(9.5)/((1/11117.0 + 1/18395.0)**0.5)\n",
    "print 't-statistic =', tval\n",
    "\n",
    "print 'cumulative distribution = ', t.cdf(tval, 11117 + 18395, loc=0, scale=1)\n",
    "p = 2* (1-t.cdf(tval, 11117 + 18395, loc=0, scale=1))\n",
    "print 'p-val = ', p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a power calculation. Let's just do a calculation on what kind of sample size we would need to detect the kind of difference we have with 80% power.\n",
    "\n",
    "So in other words $P(t_{stat} > t_{crit} | \\mu_1 - \\mu_2 = 4.07) = 80\\%$\n",
    "\n",
    "For a 2 sided t-test, t-crit ~ 2 (depending on df, we can check this assumption later).\n",
    "\n",
    "The true calculation here is:\n",
    "\n",
    "$P(t_{df} > (2 - E[t_{stat}]) = 0.8$\n",
    "\n",
    "Here we will simplify the t-distribution to a normal one, (we can check the validity of this later).\n",
    "\n",
    "So we are looking for a value that a random normal will be greater than, 80% of the time.\n",
    "\n",
    "This is just $CDF^{-1}(0.2) = -0.841621$\n",
    "\n",
    "$2 - \\dfrac{4.07}{9.5\\sqrt{\\tfrac{2}{n}}} = -0.841621$\n",
    "\n",
    "Where n is the number in each sample (assuming equal).\n",
    "\n",
    "$ n = ((2+0.84)*\\sqrt2 * 9.5 / 4.07)^2 $\n",
    "\n",
    "$(2.84*1.41*9.5/4.07)^2 = 87 $ so we expect to get 80% power with n~90, we have more than 10,000.\n",
    "\n",
    "The assumption of normality holds up. At $df\\sim2*90$, the t-distribution is nearly normal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7 Company evaluation\n",
    "\n",
    "We can look at how sales are changing month to month:\n",
    "\n",
    "```\n",
    "select sum(amount) from purchases group by month(date);\n",
    "\n",
    "+-------------+\n",
    "| sum(amount) |\n",
    "+-------------+\n",
    "|   254272.05 |\n",
    "|   164846.26 |\n",
    "|   110667.99 |\n",
    "|   104222.72 |\n",
    "|   141337.98 |\n",
    "|   141637.65 |\n",
    "|   160638.66 |\n",
    "|   166556.71 |\n",
    "|     5380.47 |\n",
    "+-------------+\n",
    "\n",
    "```\n",
    "\n",
    "There's a steep dropoff after January, (after-holiday sales?) but otherwise it looks mostly stable-ish. \n",
    "\n",
    "Also, we can count number of subscriptions beginning (and that have ended) in each year:\n",
    "\n",
    "```\n",
    "select year(start_date), count(*) as total, count(end_date) as churned from subscriptions group by year(start_date); \n",
    "\n",
    "\n",
    "+------------------+-------+---------+\n",
    "| year(start_date) | total | churned |\n",
    "+------------------+-------+---------+\n",
    "|             2012 |  3870 |    3828 |\n",
    "|             2013 | 10815 |   10564 |\n",
    "|             2014 | 31351 |   30121 |\n",
    "|             2015 | 62568 |   56017 |\n",
    "|             2016 | 45684 |   22751 |\n",
    "+------------------+-------+---------+\n",
    "\n",
    "```\n",
    "\n",
    "So it looks like overall there is pretty healthy growth in new subscriptions overall, but the churn seems high... only ~10% of subscriptions starting in 2015 are still current. About 50% of subscriptions this year have already churned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8 Active user table\n",
    "\n",
    "First create a date table with all dates from:\n",
    "\n",
    "1/9/2012 - 9/1/2016\n",
    "```\n",
    "DROP PROCEDURE IF EXISTS filldates;\n",
    "DELIMITER |\n",
    "CREATE PROCEDURE filldates(dateStart DATE, dateEnd DATE)\n",
    "BEGIN\n",
    "  WHILE dateStart <= dateEnd DO\n",
    "    INSERT INTO _date (datelist) VALUES (dateStart);\n",
    "    SET dateStart = date_add(dateStart, INTERVAL 1 DAY);\n",
    "  END WHILE;\n",
    "END;\n",
    "|\n",
    "DELIMITER ;\n",
    "CALL filldates('2012-01-09','2016-09-01');\n",
    "\n",
    "SELECT * FROM _date;\n",
    "\n",
    "...\n",
    "| 2016-08-27 |\n",
    "| 2016-08-28 |\n",
    "| 2016-08-29 |\n",
    "| 2016-08-30 |\n",
    "| 2016-08-31 |\n",
    "| 2016-09-01 |\n",
    "+------------+\n",
    "```\n",
    "\n",
    "Try to make the table\n",
    "\n",
    "```\n",
    "SELECT \n",
    "user_id, \n",
    "datelist as date, \n",
    "    (case \n",
    "    when end_date IS NULL\n",
    "    then TRUE\n",
    "    when (end_date IS NOT NULL) and (datelist<end_date)\n",
    "    then TRUE\n",
    "    else FALSE\n",
    "    end) as is_active ,\n",
    "start_date as signup_date,\n",
    "signup_platform  \n",
    "from subscriptions \n",
    "join _date \n",
    "on start_date<datelist \n",
    "join users \n",
    "on users.id = user_id\n",
    "WHERE user_id BETWEEN 100000 AND 105000;\n",
    "\n",
    "|  104997 | 2016-09-01 |         0 | 2015-12-25  | ios             |\n",
    "|  104998 | 2016-09-01 |         0 | 2015-12-25  | ios             |\n",
    "|  104999 | 2016-09-01 |         0 | 2015-12-25  | ios             |\n",
    "|  105000 | 2016-09-01 |         0 | 2015-12-25  | ios             |\n",
    "+---------+------------+-----------+-------------+-----------------+\n",
    "1288429 rows in set (1.97 sec)\n",
    "\n",
    "(FALSE evaluates to 0)\n",
    "\n",
    "```\n",
    "\n",
    "...and MySQL crashes if you don't restrict user_id\n",
    "\n",
    "To make it more efficient you could only add today's entries. Entries from the past would not change.\n",
    "\n",
    "Let's count churn by date.\n",
    "\n",
    "```\n",
    "SELECT end_date, count(end_date) as num_churn from subscriptions group by end_date;\n",
    "\n",
    "+------------+-----------+\n",
    "| end_date   | num_churn |\n",
    "+------------+-----------+\n",
    "...\n",
    "...\n",
    "...\n",
    "| 2016-08-24 |       182 |\n",
    "| 2016-08-25 |       178 |\n",
    "| 2016-08-26 |       185 |\n",
    "| 2016-08-27 |       187 |\n",
    "| 2016-08-28 |       196 |\n",
    "| 2016-08-29 |       182 |\n",
    "| 2016-08-30 |       189 |\n",
    "| 2016-08-31 |       185 |\n",
    "| 2016-09-01 |       176 |\n",
    "+------------+-----------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9 Annual vs monthly\n",
    "\n",
    "We can look at the purchase amount this year, grouped by subscription type:\n",
    "\n",
    "```\n",
    "select sum(amount), sub_type \n",
    "from purchases \n",
    "join subscriptions \n",
    "on subscriptions.user_id = purchases.user_id \n",
    "group by sub_type;\n",
    "\n",
    "+-------------+----------+\n",
    "| sum(amount) | sub_type |\n",
    "+-------------+----------+\n",
    "|    91742.75 | annual   |\n",
    "|  1178183.30 | monthly  |\n",
    "+-------------+----------+\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "So the change should definitely be made. \n",
    "\n",
    "Expected revenue increase would be ~ 0.10 * (1,200,000 - 100,000) = 110,000.\n",
    "\n",
    "Annualized this would be about 110,000/8*12 = 165,000"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
